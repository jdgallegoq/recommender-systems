{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based recommendations\n",
    "Explore how genre similarity and KNN for same year movies clusters works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some paths to download data\n",
    "ratingsPath = \"../data/ml-latest-small/ratings.csv\"\n",
    "moviesPath = \"../data/ml-latest-small/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reader instance to download data\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "# download dataset to path\n",
    "ratingsDataset = Dataset.load_from_file(ratingsPath, reader=reader)\n",
    "ratingsDataset = ratingsDataset.build_full_trainset()\n",
    "\n",
    "# now it is important to get popularity ranks to get some metrics\n",
    "ratings = defaultdict(int)\n",
    "rankings = defaultdict(int)\n",
    "with open(ratingsPath, newline='') as csvfile:\n",
    "    ratingReader = csv.reader(csvfile)\n",
    "    next(ratingReader)\n",
    "    for row in ratingReader:\n",
    "        movieID = int(row[1])\n",
    "        ratings[movieID] += 1\n",
    "    rank = 1\n",
    "    for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        rankings[movieID] = rank\n",
    "        rank +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an additional feature dataset for the movielens dataset\n",
    "mes = defaultdict(list)\n",
    "with open(\"../data/ml-latest-small/LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
    "    mesReader = csv.reader(csvfile)\n",
    "    next(mesReader)\n",
    "    for row in mesReader:\n",
    "        movieID = int(row[0])\n",
    "        avgShotLength = float(row[1])\n",
    "        meanColorVariance = float(row[2])\n",
    "        stddevColorVariance = float(row[3])\n",
    "        meanMotion = float(row[4])\n",
    "        stddevMotion = float(row[5])\n",
    "        meanLightingKey = float(row[6])\n",
    "        numShots = float(row[7])\n",
    "        mes[movieID] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
    "            meanMotion, stddevMotion, meanLightingKey, numShots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get movie genres\n",
    "genres = defaultdict(list)\n",
    "genreIDs = {}\n",
    "maxGenreID = 0\n",
    "with open(moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "    movieReader = csv.reader(csvfile)\n",
    "    next(movieReader)\n",
    "    for row in movieReader:\n",
    "        movieID = int(row[0])\n",
    "        genreList = row[2].split('|')\n",
    "        genreIDList = []\n",
    "        for genre in genreList:\n",
    "            if genre in genreIDs:\n",
    "                genreID = genreIDs[genre]\n",
    "            else:\n",
    "                genreID = maxGenreID\n",
    "                genreIDs[genre] = genreID\n",
    "                maxGenreID += 1\n",
    "            genreIDList.append(genreID)\n",
    "        genres[movieID] = genreIDList\n",
    "\n",
    "# genres has a dict that has genres encoded as integers\n",
    "# so the goal is to convert those to bitfields to it can be\n",
    "# treated as vectors\n",
    "for (movieID, genreIDList) in genres.items():\n",
    "    bitfield = [0] * maxGenreID\n",
    "    for genreID in genreIDList:\n",
    "        bitfield[genreID] = 1\n",
    "    genres[movieID] = bitfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get years\n",
    "p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
    "years = defaultdict(int)\n",
    "with open(moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "    movieReader = csv.reader(csvfile)\n",
    "    next(movieReader)\n",
    "    for row in movieReader:\n",
    "        movieID = int(row[0])\n",
    "        title = row[1]\n",
    "        m = p.search(title)\n",
    "        year = m.group(1)\n",
    "        if year:\n",
    "            years[movieID] = int(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to compute genre similarity\n",
    "def computeGenreSimilarity(movie1, movie2, genres):\n",
    "    genres1 = genres[movie1]\n",
    "    genres2 = genres[movie2]\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(genres1)):\n",
    "        x = genres1[i]\n",
    "        y = genres2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    \n",
    "    return sumxy / math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate years similarity\n",
    "def computeYearSimilarity(movie1, movie2, years):\n",
    "    \"\"\"\n",
    "    this function penalizes large diferences in years (by 10 scale).\n",
    "    exponential decay\n",
    "    \"\"\"\n",
    "    diff = abs(years[movie1] - years[movie2])\n",
    "    sim = math.exp(-diff/10.0)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n"
     ]
    }
   ],
   "source": [
    "# compute genre distance for every movie combination as a 2x2 matrix\n",
    "similarities = np.zeros((ratingsDataset.n_items, ratingsDataset.n_items))\n",
    "for thisRating in range(ratingsDataset.n_items):\n",
    "    if (thisRating % 100 == 0):\n",
    "        print(thisRating, \" of \", ratingsDataset.n_items)\n",
    "    for otherRating in range(thisRating+1, ratingsDataset.n_items):\n",
    "        thisMovieID = int(ratingsDataset.to_raw_iid(thisRating))\n",
    "        otherMovieID = int(ratingsDataset.to_raw_iid(otherRating))\n",
    "        genreSimilarity = computeGenreSimilarity(thisMovieID, otherMovieID, genres)\n",
    "        yearSimilarity = computeYearSimilarity(thisMovieID, otherMovieID, years)\n",
    "        # compute a final similarity score combining both genre and year similarity\n",
    "        similarities[thisRating, otherRating] = genreSimilarity * yearSimilarity\n",
    "        similarities[otherRating, thisRating] = similarities[thisRating, otherRating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "from surprise import PredictionImpossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get anti test set for an specific user\n",
    "def GetAntiTestSetForUser(testSubject):\n",
    "    trainset = Dataset.load_from_file(ratingsPath, reader=reader).build_full_trainset()\n",
    "    fill = trainset.global_mean\n",
    "    anti_testet = []\n",
    "    u = trainset.to_inner_uid(str(testSubject))\n",
    "    user_items = set([j for (j, _) in trainset.ur[u]])\n",
    "    anti_testet += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
    "                      i in trainset.all_items() if \n",
    "                      i not in user_items]\n",
    "\n",
    "    return anti_testet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to estimate KNN for a given user and item\n",
    "k = 40 # parameter for KNN neighbors\n",
    "def estimate(u, i):\n",
    "    if not (ratingsDataset.knows_user(u) and ratingsDataset.knows_item(i)):\n",
    "        raise PredictionImpossible('User and/or items unkown')\n",
    "\n",
    "    # build similarities between item and everything the user rated\n",
    "    neighbors = []\n",
    "    for rating in ratingsDataset.ur[u]:\n",
    "        genreSimilarity = similarities[i, rating[0]]\n",
    "        neighbors.append((genreSimilarity, rating[1]))\n",
    "    \n",
    "    # extract top-k most-similar ratings\n",
    "    k_neighbors = heapq.nlargest(k, neighbors, key=lambda t: t[0])\n",
    "\n",
    "    # compute average sim score of k neighbors weightes by user ratings\n",
    "    simTotal = weightedSum = 0\n",
    "    for (simScore, rating) in k_neighbors:\n",
    "        if (simScore > 0):\n",
    "            simTotal += simScore\n",
    "            weightedSum += simScore * rating\n",
    "    \n",
    "    if (simTotal==0):\n",
    "        raise PredictionImpossible('No neighbors')\n",
    "    \n",
    "    predictedRating = weightedSum / simTotal\n",
    "\n",
    "    return predictedRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see recomendations for some user\n",
    "testSubject = 85\n",
    "testSet = GetAntiTestSetForUser(testSubject)\n",
    "content_knn = AlgoBase.fit(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender_systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
