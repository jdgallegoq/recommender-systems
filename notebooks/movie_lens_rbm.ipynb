{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Bolztman Machines (RBM)\n",
    "Recommendations based on Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some paths to download data\n",
    "ratingsPath = \"../data/ml-latest-small/ratings.csv\"\n",
    "moviesPath = \"../data/ml-latest-small/movies.csv\"\n",
    "\n",
    "# define reader instance to download data\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "# download dataset to path\n",
    "ratingsDataset = Dataset.load_from_file(ratingsPath, reader=reader)\n",
    "\n",
    "# now parse movies dataset\n",
    "movieID_to_name = {}\n",
    "name_to_movieID = {}\n",
    "with open(moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "    movieReader = csv.reader(csvfile)\n",
    "    next(movieReader)\n",
    "    for row in movieReader:\n",
    "        movieID = int(row[0])\n",
    "        movieName = row[1]\n",
    "        movieID_to_name[movieID] = movieName\n",
    "        name_to_movieID[movieName] = movieID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user ratings from ratingsDataset based on user\n",
    "def getUserRatings(user):\n",
    "    userRatings = []\n",
    "    hitUser = False\n",
    "    with open(ratingsPath, newline='') as csvfile:\n",
    "        ratingReader = csv.reader(csvfile)\n",
    "        next(ratingReader)\n",
    "        for row in ratingReader:\n",
    "            userID = int(row[0])\n",
    "            if (user == userID):\n",
    "                movieID = int(row[1])\n",
    "                rating = float(row[2])\n",
    "                userRatings.append((movieID, rating))\n",
    "                hitUser = True\n",
    "            if (hitUser and (user != userID)):\n",
    "                break\n",
    "\n",
    "    return userRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it is important to get popularity ranks to get some metrics\n",
    "ratings = defaultdict(int)\n",
    "rankings = defaultdict(int)\n",
    "with open(ratingsPath, newline='') as csvfile:\n",
    "    ratingReader = csv.reader(csvfile)\n",
    "    next(ratingReader)\n",
    "    for row in ratingReader:\n",
    "        movieID = int(row[1])\n",
    "        ratings[movieID] += 1\n",
    "    rank = 1\n",
    "    for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        rankings[movieID] = rank\n",
    "        rank +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the RBM arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.17.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            visibleDimensions,\n",
    "            epochs=20,\n",
    "            hiddenDimensions=50,\n",
    "            ratingValues=10,\n",
    "            learningRate=0.001,\n",
    "            batchSize=100\n",
    "            ):\n",
    "        \n",
    "       self.visibleDimensions = visibleDimensions\n",
    "       self.epochs = epochs\n",
    "       self.hiddenDimensions = hiddenDimensions\n",
    "       self.ratingValues = ratingValues\n",
    "       self.learningRate = learningRate\n",
    "       self.batchSize = batchSize\n",
    "\n",
    "    def Train(self, X):\n",
    "        # init weights as done in original paper\n",
    "        maxWeight = -4.0 * np.sqrt(6.0/(self.hiddenDimensions + self.visibleDimensions))\n",
    "        self.weights = tf.Variable(\n",
    "            tf.random.uniform([self.visibleDimensions, self.hiddenDimensions],minval=-maxWeight, maxval=maxWeight),\n",
    "            tf.float32,\n",
    "            name='weights'\n",
    "        )\n",
    "        self.hiddenBias = tf.Variable(\n",
    "            tf.zeros([self.hiddenDimensions]),\n",
    "            tf.float32,\n",
    "            name='hiddenBias'\n",
    "        )\n",
    "        self.visibleBias = tf.Variable(\n",
    "            tf.zeros([self.visibleDimensions]),\n",
    "            tf.float32,\n",
    "            name='visibleBias'\n",
    "        )\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            trX = np.array(X)\n",
    "            for i in range(0, trX.shape[0], self.batchSize):\n",
    "                epochX = trX[i:i+self.batchSize]\n",
    "                self.MakeGraph(epochX)\n",
    "            print(\"Trained epoch \", epoch)\n",
    "    \n",
    "    def GetRecommendations(self, inputUser):\n",
    "        feed = self.MakeHidden(inputUser)\n",
    "        rec = self.MakeVisible(feed)\n",
    "        return rec[0]\n",
    "    \n",
    "    def MakeGraph(self, inputUser):\n",
    "        \"\"\"\n",
    "        Performs Gibbs sampling for contrastive divergence. The paper it is assuime k=1 of iterating\n",
    "        over the forward pass multiple times since it seems to work just fine\n",
    "        \"\"\"\n",
    "        # ----------- Forward pass ----------- #\n",
    "        # get tensor of hidden probabilities\n",
    "        hProb0 = tf.nn.sigmoid(tf.matmul(inputUser, self.weights) + self.hiddenBias)\n",
    "        # sample from all distributions\n",
    "        hSample = tf.nn.relu(tf.sign(hProb0 - tf.random.uniform(tf.shape(hProb0))))\n",
    "        # Stitch it toguether\n",
    "        forward = tf.matmul(tf.transpose(inputUser), hSample)\n",
    "\n",
    "        # ----------- Backward pass ----------- #\n",
    "        # reconstruct visible layer given hidden layer sample\n",
    "        v = tf.matmul(hSample, tf.transpose(self.weights)) + self.visibleBias\n",
    "        # build up mask for hidden ratings\n",
    "        vMask = tf.sign(inputUser)\n",
    "        VMask3D = tf.reshape(vMask, [tf.shape(v)[0], -1, self.ratingValues]) # reshape of individual ratings\n",
    "        VMask3D = tf.reduce_max(VMask3D, axis=[2], keepdims=True) # ensure 1 for exiting ratings and 0 for missing ones\n",
    "\n",
    "        # extract rating vectors for each individual\n",
    "        v = tf.reshape(v, [tf.shape(v)[0], -1, self.ratingValues])\n",
    "        vProb = tf.nn.softmax(v*VMask3D)\n",
    "        vProb = tf.reshape(vProb, [tf.shape(v)[0], -1])\n",
    "        hProb1 = tf.nn.sigmoid(tf.matmul(vProb, self.weights) + self.hiddenBias)\n",
    "        backward = tf.matmul(tf.transpose(vProb), hProb1)\n",
    "\n",
    "        # ----------- Run passes ----------- #\n",
    "        weighupdate = self.weights.assign_add(self.learningRate * (forward - backward))\n",
    "        hiddenBiasUpdate = self.hiddenBias.assign_add(self.learningRate * tf.reduce_mean(hProb0 - hProb1, 0))\n",
    "        visibleBiasUpdate = self.visibleBias.assign_add(self.learningRate * tf.reduce_mean(inputUser - vProb, 0))\n",
    "\n",
    "        self.update = [weighupdate, hiddenBiasUpdate, visibleBiasUpdate]\n",
    "\n",
    "    def MakeHidden(self, inputUser):\n",
    "        hidden = tf.nn.sigmoid(tf.matmul(inputUser, self.weights) + self.hiddenBias)\n",
    "        self.MakeGraph(inputUser)\n",
    "        return hidden\n",
    "    \n",
    "    def MakeVisible(self, feed):\n",
    "        visible = tf.nn.sigmoid(tf.matmul(feed, tf.transpose(self.weights)) + self.visibleBias)\n",
    "        return visible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RBM wrapper with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "from surprise import PredictionImpossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBMAlgorithm(AlgoBase):\n",
    "    def __init__(self, epochs=20, hiddenDim=100, learningRate=0.001, batchSize=100, sim_options={}):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.epochs = epochs\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.learningRate = learningRate\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "\n",
    "        numUsers = trainset.n_users\n",
    "        numItems = trainset.n_items\n",
    "\n",
    "        trainingMatrix = np.zeros([numUsers, numItems, 10], dtype=np.float32)\n",
    "        for (uid, iid, rating) in trainset.all_ratings():\n",
    "            adjustRating = int(float(rating)*2.0) - 1\n",
    "            trainingMatrix[int(uid), int(iid), adjustRating] = 1\n",
    "        \n",
    "        trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
    "\n",
    "        # create RBM with (n_items * rating_values) visible nodes\n",
    "        rbm = RBM(\n",
    "            trainingMatrix.shape[1],\n",
    "            hiddenDimensions=self.hiddenDim,\n",
    "            learningRate=self.learningRate,\n",
    "            batchSize=self.batchSize,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "        rbm.Train(trainingMatrix)\n",
    "        \n",
    "        self.predictedRatings = np.zeros([numUsers, numItems], dtype=np.float32)\n",
    "        for uiid in range(trainset.n_users):\n",
    "            if (uiid % 50 == 0):\n",
    "                print(\"Processing user \", uiid)\n",
    "            recs = rbm.GetRecommendations([trainingMatrix[uiid]])\n",
    "            recs = np.reshape(recs, [numItems, 10])\n",
    "            # take a normalized rating using it as epectation (prediction)\n",
    "            for itemID, rec in enumerate(recs):\n",
    "                normalized = self.softmax(rec)\n",
    "                rating = np.average(np.arange(10), weights=normalized)\n",
    "                self.predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unknown')\n",
    "        \n",
    "        rating = self.predictedRatings[u, i]\n",
    "        if (rating < 0.001):\n",
    "            raise PredictionImpossible('No valid prediction exists')\n",
    "        \n",
    "        return rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some recomendations based on RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Framework.EvaluationData import EvaluationData\n",
    "from Framework.RecommenderMetrics import RecommenderMetrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "RMSE SVD 1.150206709882802\n",
      "MAE SVD 0.956557487078616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define evaluation data\n",
    "# get evaluation data\n",
    "evaluationData = EvaluationData(ratingsDataset, rankings)\n",
    "# define RBM instance\n",
    "rbm = RBMAlgorithm(epochs=20)\n",
    "rbm.fit(ratingsDataset.build_full_trainset())\n",
    "predictions = rbm.test(evaluationData.GetTestSet())\n",
    "print(\"RMSE SVD\", RecommenderMetrics.RMSE(predictions))\n",
    "print(\"MAE SVD\", RecommenderMetrics.MAE(predictions))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to ger movie name based on movie ID\n",
    "def getMovieName(movieID):\n",
    "    if movieID in movieID_to_name:\n",
    "        return movieID_to_name[movieID]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## RBM recommendations ##########\n",
      "Lives of Others, The (Das leben der Anderen) (2006) 3.2998502\n",
      "Limitless (2011) 3.2895017\n",
      "Logan (2017) 3.2853334\n",
      "Maltese Falcon, The (1941) 3.2836244\n",
      "Hustler, The (1961) 3.2824562\n",
      "Captain Phillips (2013) 3.2796102\n",
      "Boot, Das (Boat, The) (1981) 3.278512\n",
      "Harold and Maude (1971) 3.2742562\n",
      "Untitled Spider-Man Reboot (2017) 3.2712727\n",
      "Touch of Evil (1958) 3.2711432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see recomendations\n",
    "# let's see some recommendations\n",
    "testSubject = 85\n",
    "k = 10\n",
    "\n",
    "trainSet = evaluationData.GetFullTrainSet()\n",
    "testSet = evaluationData.GetAntiTestSetForUser(testSubject)\n",
    "\n",
    "predictions = rbm.test(testSet)\n",
    "recommendations = []\n",
    "for userID, movieID, actualRating, EstimatedRating, _ in predictions:\n",
    "    intMovieID = int(movieID)\n",
    "    recommendations.append((intMovieID, EstimatedRating))\n",
    "\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"#\"*10, \"RBM recommendations\", \"#\"*10)\n",
    "for ratings in recommendations[:k]:\n",
    "    print(getMovieName(ratings[0]), ratings[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n",
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n"
     ]
    }
   ],
   "source": [
    "# define a param grid\n",
    "param_grid = {'hiddenDim': [20, 10], 'learningRate': [0.1, 0.01]}\n",
    "gs = GridSearchCV(RBMAlgorithm, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(ratingsDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score attained:  1.1342662605735316\n",
      "{'hiddenDim': 10, 'learningRate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# now explore best metrics and params\n",
    "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender_systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
