{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Item Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import heapq\n",
    "from surprise import KNNBasic\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some paths to download data\n",
    "ratingsPath = \"../data/ml-latest-small/ratings.csv\"\n",
    "moviesPath = \"../data/ml-latest-small/movies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reader instance to download data\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "# download dataset to path\n",
    "ratingsDataset = Dataset.load_from_file(ratingsPath, reader=reader)\n",
    "ratingsDataset = ratingsDataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read movies info\n",
    "movieID_to_name = {}\n",
    "name_to_movieID = {}\n",
    "with open(moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
    "    movieReader = csv.reader(csvfile)\n",
    "    next(movieReader)  #Skip header line\n",
    "    for row in movieReader:\n",
    "        movieID = int(row[0])\n",
    "        movieName = row[1]\n",
    "        movieID_to_name[movieID] = movieName\n",
    "        name_to_movieID[movieName] = movieID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get movie name\n",
    "def getMovieName(movieID):\n",
    "    if movieID in movieID_to_name:\n",
    "        return movieID_to_name[movieID]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# define similarity options and get similarity matrix\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    # set to flase cause this one is item based\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(ratingsDataset)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get top-N recommendations for a test user\n",
    "testSubject = '85'\n",
    "k = 10\n",
    "\n",
    "testUserInnerID = ratingsDataset.to_inner_uid(testSubject)\n",
    "# get top K the test subject rated\n",
    "testUserRatings = ratingsDataset.ur[testUserInnerID]\n",
    "kNeighbors = heapq.nlargest(k, testUserRatings, key=lambda t: t[1])\n",
    "\n",
    "# get similar items to thing the test subject liked (weighted by rating)\n",
    "candidates = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust (1990) 8.993195870740706\n",
      "Night Porter, The (Portiere di notte, Il) (1974) 8.991602228017534\n",
      "Daytrippers, The (1996) 8.978892697759282\n",
      "Living in Oblivion (1995) 8.973090760365785\n",
      "Melvin and Howard (1980) 8.970142500145332\n",
      "Hate (Haine, La) (1995) 8.967270202229166\n",
      "Presidio, The (1988) 8.96429313204702\n",
      "Stop Making Sense (1984) 8.954691793826552\n",
      "Color Purple, The (1985) 8.954276360003217\n",
      "Opposite of Sex, The (1998) 8.95170801390616\n",
      "Clue (1985) 8.949644625955322\n"
     ]
    }
   ],
   "source": [
    "# build a dict of stuff the test user already seen\n",
    "watched = {}\n",
    "for itemID, rating in ratingsDataset.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1\n",
    "\n",
    "# get top-rated items from similar items\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = ratingsDataset.to_raw_iid(itemID)\n",
    "        print(getMovieName(int(movieID)), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how results change by defining a threshold on items rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opposite of Sex, The (1998) 10.94172656584623\n",
      "American in Paris, An (1951) 10.936427200000246\n",
      "One Fine Day (1996) 10.934890689782453\n",
      "Last Picture Show, The (1971) 10.931806486265977\n",
      "Gilda (1946) 10.929912059633953\n",
      "Dead Calm (1989) 10.916981536391042\n",
      "Streetcar Named Desire, A (1951) 10.91594253451208\n",
      "Five Easy Pieces (1970) 10.914690389589753\n",
      "Out of the Past (1947) 10.910660929932783\n",
      "Killer, The (Die xue shuang xiong) (1989) 10.90933848448976\n",
      "Born Yesterday (1950) 10.909227888131605\n"
     ]
    }
   ],
   "source": [
    "# take all items with a rate of 4.0 or greater\n",
    "kNeighbors = []\n",
    "for rating in testUserRatings:\n",
    "    if rating[1] > 4.0:\n",
    "        kNeighbors.append(rating)\n",
    "\n",
    "# get similar items to thing the test subject liked (weighted by rating)\n",
    "candidates = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating/5.0)\n",
    "\n",
    "# get top-rated items from similar items\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = ratingsDataset.to_raw_iid(itemID)\n",
    "        print(getMovieName(int(movieID)), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Framework.EvaluationData import EvaluationData\n",
    "from Framework.RecommenderMetrics import RecommenderMetrics\n",
    "\n",
    "from surprise.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# get rankings and ratings based on data\n",
    "ratingsDataset = Dataset.load_from_file(ratingsPath, reader=reader)\n",
    "ratings = defaultdict(int)\n",
    "rankings = defaultdict(int)\n",
    "with open(ratingsPath, newline='') as csvfile:\n",
    "    ratingReader = csv.reader(csvfile)\n",
    "    next(ratingReader)\n",
    "    for row in ratingReader:\n",
    "        movieID = int(row[1])\n",
    "        ratings[movieID] += 1\n",
    "    rank = 1\n",
    "    for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        rankings[movieID] = rank\n",
    "        rank +=1\n",
    "\n",
    "# define evaluation data based on original data\n",
    "evalData = EvaluationData(ratingsDataset, rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# train on leave-one-out\n",
    "trainSet = evalData.GetLOOCVTrainSet()\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftOutTestSet = evalData.GetLOOCVTestSet()\n",
    "# build dict to lists of (int(movieID), predictedrating) pairs\n",
    "topN = defaultdict(list)\n",
    "k = 10\n",
    "for uiid in range(trainSet.n_users):\n",
    "    # get top N similar users to test subject\n",
    "    userRatings = trainSet.ur[uiid]\n",
    "    kNeighbors = heapq.nlargest(k, userRatings, key=lambda t: t[1])\n",
    "    # get candidates weighted by user rating\n",
    "    candidates = defaultdict(float)\n",
    "    for itemID, rating in kNeighbors:\n",
    "        similarityRow = simsMatrix[itemID]\n",
    "        for innerID, score in enumerate(similarityRow):\n",
    "            candidates[innerID] += score * (rating / 5.0)\n",
    "    \n",
    "    # build a dict of stuff the user already watched\n",
    "    watched = {}\n",
    "    for itemID, rating in trainSet.ur[uiid]:\n",
    "        watched[itemID] = 1\n",
    "    \n",
    "    # get top-rated items from similar users\n",
    "    pos = 0\n",
    "    for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "        if not itemID in watched:\n",
    "            movieID = trainSet.to_raw_iid(itemID)\n",
    "            topN[int(trainSet.to_raw_uid(uiid))].append((int(movieID), 0.0))\n",
    "            pos += 1\n",
    "            if (pos > 40):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit-rate 0.0\n"
     ]
    }
   ],
   "source": [
    "# print hit-rate or mesure of interest\n",
    "print(\"hit-rate\", RecommenderMetrics.HitRate(topN, leftOutTestSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data could be driven to worse results based on item based approach. Even though this needs to be teste online with A/B test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender_systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
